{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b941bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 671 images: ['Helmet', 'Person_no_helmet', 'no_person']\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "\u001b[1m82420632/82420632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1us/step\n",
      "Training EfficientNetV2S model...\n",
      "Epoch 1/25\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.8750 - loss: 0.3150 - val_accuracy: 1.0000 - val_loss: 0.1092 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m 1/31\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.7143 - loss: 1.2253"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 706ms/step - accuracy: 0.7143 - loss: 1.2253 - val_accuracy: 1.0000 - val_loss: 0.1111 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.9815 - loss: 0.0582 - val_accuracy: 0.9940 - val_loss: 0.0545 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 714ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0493 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.9897 - loss: 0.0363 - val_accuracy: 0.9940 - val_loss: 0.0352 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 814ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9940 - val_loss: 0.0337 - learning_rate: 0.0010\n",
      "Fine-tuning model...\n",
      "Epoch 1/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 4s/step - accuracy: 0.9795 - loss: 0.0912 - val_accuracy: 1.0000 - val_loss: 0.1088 - learning_rate: 1.0000e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 696ms/step - accuracy: 0.8750 - loss: 0.2761 - val_accuracy: 1.0000 - val_loss: 0.1077 - learning_rate: 1.0000e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 3s/step - accuracy: 0.9877 - loss: 0.0460 - val_accuracy: 1.0000 - val_loss: 0.0851 - learning_rate: 1.0000e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 694ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 1.0000 - val_loss: 0.0821 - learning_rate: 2.0000e-06\n",
      "Epoch 5/15\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step - accuracy: 0.9836 - loss: 0.0573 - val_accuracy: 1.0000 - val_loss: 0.0587 - learning_rate: 2.0000e-06\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy: 1.0000\n",
      "Model saved as 'helmet_efficientnetv2.h5'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetV2S\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "\n",
    "# Load dataset (same structure as before)\n",
    "class SimpleDatasetLoader:\n",
    "    def __init__(self, preprocessors=None):\n",
    "        self.preprocessors = preprocessors if preprocessors else []\n",
    "    \n",
    "    def load(self, image_paths, verbose=1):\n",
    "        data, labels = [], []\n",
    "        class_names = sorted(os.listdir('Helmet_Dataset'))\n",
    "        \n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            class_path = os.path.join('Helmet_Dataset', class_name)\n",
    "            image_paths = glob.glob(os.path.join(class_path, \"*.jpg\")) + \\\n",
    "                         glob.glob(os.path.join(class_path, \"*.png\")) + \\\n",
    "                         glob.glob(os.path.join(class_path, \"*.jpeg\"))\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:\n",
    "                    image = cv2.resize(image, (380, 380))  # EfficientNetV2S input size\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    data.append(image)\n",
    "                    labels.append(class_idx)\n",
    "        \n",
    "        return np.array(data), np.array(labels), class_names\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dl = SimpleDatasetLoader()\n",
    "(data, labels, class_names) = dl.load('Helmet_Dataset')\n",
    "print(f\"Loaded {len(data)} images: {class_names}\")\n",
    "\n",
    "# Split data\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42, stratify=labels)\n",
    "\n",
    "# Advanced data augmentation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "# Build EfficientNetV2S (State-of-the-art CNN 2025)\n",
    "base_model = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(380, 380, 3))\n",
    "base_model.trainable = False  # Start with frozen base\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(len(class_names), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"Training EfficientNetV2S model...\")\n",
    "history = model.fit(\n",
    "    train_datagen.flow(trainX, trainY, batch_size=16),  # Smaller batch for PC\n",
    "    steps_per_epoch=len(trainX)//16,\n",
    "    epochs=25,\n",
    "    validation_data=val_datagen.flow(testX, testY, batch_size=16),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Unfreeze top layers for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:  # Fine-tune last 20 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),  # Lower LR for fine-tuning\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning model...\")\n",
    "history_fine = model.fit(\n",
    "    train_datagen.flow(trainX, trainY, batch_size=16),\n",
    "    steps_per_epoch=len(trainX)//16,\n",
    "    epochs=15,\n",
    "    validation_data=val_datagen.flow(testX, testY, batch_size=16),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Final evaluation\n",
    "test_loss, test_acc = model.evaluate(testX, testY)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model.save('Models/helmet_efficientnetv2.h5')\n",
    "print(\"Model saved as 'helmet_efficientnetv2.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ae9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Person_no_helmet\n",
      "Confidence: 57.22%\n",
      "All probabilities: {'Helmet': np.float32(0.17703603), 'no_person': np.float32(0.25074992), 'Person_no_helmet': np.float32(0.572214)}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model('Models/helmet_efficientnetv2.h5')\n",
    "class_names = ['Helmet', 'no_person', 'Person_no_helmet']\n",
    "\n",
    "def predict_single_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (380, 380))\n",
    "    img = np.expand_dims(img, axis=0) / 255.0\n",
    "    \n",
    "    predictions = model.predict(img, verbose=0)[0]\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    confidence = predictions[predicted_class]\n",
    "    \n",
    "    print(f\"Predicted: {class_names[predicted_class]}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    print(f\"All probabilities: {dict(zip(class_names, predictions))}\")\n",
    "    return class_names[predicted_class], confidence\n",
    "\n",
    "# Test\n",
    "result, conf = predict_single_image('Test_Files/Person_with_helmet_3.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94757320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e1f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15297f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
